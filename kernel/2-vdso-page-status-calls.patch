From 248e6427ed556a6fc1f6bc56d30b5ff58c641749 Mon Sep 17 00:00:00 2001
From: Anil Yelam <yelama@vmware.com>
Date: Wed, 1 Jun 2022 12:33:21 -0700
Subject: [PATCH 2/2] adding vDSO calls for page mapping and wrprotect checks

---
 arch/x86/Kconfig                            |  1 +
 arch/x86/entry/vdso/Makefile                |  1 +
 arch/x86/entry/vdso/vdso.lds.S              |  2 ++
 arch/x86/entry/vdso/vpage_map_check.S       | 38 ++++++++++++++++++++
 arch/x86/entry/vdso/vpage_wrprotect_check.S | 39 +++++++++++++++++++++
 arch/x86/mm/fault.c                         | 18 ++++++++--
 lib/vdso/Kconfig                            |  5 +++
 mm/mprotect.c                               |  9 +++++
 8 files changed, 110 insertions(+), 3 deletions(-)
 create mode 100644 arch/x86/entry/vdso/vpage_map_check.S
 create mode 100644 arch/x86/entry/vdso/vpage_wrprotect_check.S

diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig
index 7b6dd10b162a..42fc0281559a 100644
--- a/arch/x86/Kconfig
+++ b/arch/x86/Kconfig
@@ -135,6 +135,7 @@ config X86
 	select GENERIC_TIME_VSYSCALL
 	select GENERIC_GETTIMEOFDAY
 	select GENERIC_VDSO_TIME_NS
+	select GENERIC_VDSO_PAGE_CHECKS
 	select GUP_GET_PTE_LOW_HIGH		if X86_PAE
 	select HARDIRQS_SW_RESEND
 	select HARDLOCKUP_CHECK_TIMESTAMP	if X86_64
diff --git a/arch/x86/entry/vdso/Makefile b/arch/x86/entry/vdso/Makefile
index 02e3e42f380b..e692fa83d1af 100644
--- a/arch/x86/entry/vdso/Makefile
+++ b/arch/x86/entry/vdso/Makefile
@@ -28,6 +28,7 @@ vobjs-y := vdso-note.o vclock_gettime.o vgetcpu.o
 vobjs32-y := vdso32/note.o vdso32/system_call.o vdso32/sigreturn.o
 vobjs32-y += vdso32/vclock_gettime.o
 vobjs-$(CONFIG_X86_SGX)	+= vsgx.o
+vobjs-$(CONFIG_GENERIC_VDSO_PAGE_CHECKS) += vpage_map_check.o vpage_wrprotect_check.o
 
 # files to link into kernel
 obj-y				+= vma.o extable.o
diff --git a/arch/x86/entry/vdso/vdso.lds.S b/arch/x86/entry/vdso/vdso.lds.S
index 4bf48462fca7..343ff93075ca 100644
--- a/arch/x86/entry/vdso/vdso.lds.S
+++ b/arch/x86/entry/vdso/vdso.lds.S
@@ -28,6 +28,8 @@ VERSION {
 		clock_getres;
 		__vdso_clock_getres;
 		__vdso_sgx_enter_enclave;
+		__vdso_is_page_mapped;
+		__vdso_is_page_mapped_and_wrprotected;
 	local: *;
 	};
 }
diff --git a/arch/x86/entry/vdso/vpage_map_check.S b/arch/x86/entry/vdso/vpage_map_check.S
new file mode 100644
index 000000000000..f15e182a013d
--- /dev/null
+++ b/arch/x86/entry/vdso/vpage_map_check.S
@@ -0,0 +1,38 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+
+#include <linux/linkage.h>
+#include <asm/export.h>
+#include <asm/errno.h>
+#include <asm/enclu.h>
+
+#include "extable.h"
+
+.code64
+.section .text, "ax"
+
+SYM_FUNC_START(__vdso_is_page_mapped)
+	/* Prolog */
+	.cfi_startproc
+	push	%rbp
+	.cfi_adjust_cfa_offset	8
+	.cfi_rel_offset		%rbp, 0
+	mov	%rsp, %rbp
+	.cfi_def_cfa_register	%rbp
+	mov	$1ll, %rax	/* set true */
+
+.Laccess_page:
+	movb	(%rdi), %dil
+.Lout:
+	/* Epilog */
+	pop	%rbp
+	.cfi_def_cfa		%rsp, 8
+	ret
+
+.Lhandle_exception:
+	xor	%rax, %rax	/* set false */
+	jmp	.Lout
+	.cfi_endproc
+ASM_VDSO_EXTABLE_HANDLE .Laccess_page, .Lhandle_exception,		\
+			(1<<X86_TRAP_PF), ASM_VDSO_ASYNC_FLAGS
+
+SYM_FUNC_END(__vdso_is_page_mapped)
diff --git a/arch/x86/entry/vdso/vpage_wrprotect_check.S b/arch/x86/entry/vdso/vpage_wrprotect_check.S
new file mode 100644
index 000000000000..1efd8e1b7019
--- /dev/null
+++ b/arch/x86/entry/vdso/vpage_wrprotect_check.S
@@ -0,0 +1,39 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+
+#include <linux/linkage.h>
+#include <asm/export.h>
+#include <asm/errno.h>
+#include <asm/enclu.h>
+
+#include "extable.h"
+
+.code64
+.section .text, "ax"
+
+SYM_FUNC_START(__vdso_is_page_mapped_and_wrprotected)
+	/* Prolog */
+	.cfi_startproc
+	push	%rbp
+	.cfi_adjust_cfa_offset	8
+	.cfi_rel_offset		%rbp, 0
+	mov	%rsp, %rbp
+	.cfi_def_cfa_register	%rbp
+	mov	$1ll, %rax	/* set true */
+
+.Lwrite_page:
+	andb $0xff, (%rdi)
+	
+.Lout:
+	/* Epilog */
+	pop	%rbp
+	.cfi_def_cfa		%rsp, 8
+	ret
+.Lhandle_exception:
+	xor	%rax, %rax	/* set false */
+	jmp	.Lout
+	.cfi_endproc
+	
+ASM_VDSO_EXTABLE_HANDLE .Lwrite_page, .Lhandle_exception,		\
+	(1<<X86_TRAP_PF), ASM_VDSO_ASYNC_FLAGS
+
+SYM_FUNC_END(__vdso_is_page_mapped_and_wrprotected)
diff --git a/arch/x86/mm/fault.c b/arch/x86/mm/fault.c
index f1f1b5a0956a..179c5c5713da 100644
--- a/arch/x86/mm/fault.c
+++ b/arch/x86/mm/fault.c
@@ -1407,9 +1407,9 @@ void do_user_addr_fault(struct pt_regs *regs,
 	 */
 	if (unlikely((fault & VM_FAULT_RETRY) &&
 		     (flags & FAULT_FLAG_ALLOW_RETRY))) {
-		flags |= FAULT_FLAG_TRIED;
-		goto retry;
-	}
+			flags |= FAULT_FLAG_TRIED;
+			goto retry;
+		}
 
 	mmap_read_unlock(mm);
 	if (unlikely(fault & VM_FAULT_ERROR)) {
@@ -1466,6 +1466,18 @@ DEFINE_IDTENTRY_RAW_ERRORCODE(exc_page_fault)
 
 	prefetchw(&current->mm->mmap_lock);
 
+	/*
+	 * Return right away if this exception is coming from the 
+	 * page status check vDSO calls
+	 */
+	if (user_mode(regs)) {
+		if (IS_ENABLED(CONFIG_GENERIC_VDSO_PAGE_CHECKS) &&
+			is_async_vdso_exception(regs, X86_TRAP_PF)) {
+				fixup_vdso_exception(regs, X86_TRAP_PF, error_code, address);
+				return;
+		}
+	}
+
 	/*
 	 * KVM uses #PF vector to deliver 'page not present' events to guests
 	 * (asynchronous page fault mechanism). The event happens when a
diff --git a/lib/vdso/Kconfig b/lib/vdso/Kconfig
index d883ac299508..03fa4d90aebe 100644
--- a/lib/vdso/Kconfig
+++ b/lib/vdso/Kconfig
@@ -30,4 +30,9 @@ config GENERIC_VDSO_TIME_NS
 	  Selected by architectures which support time namespaces in the
 	  VDSO
 
+config GENERIC_VDSO_PAGE_CHECKS
+	bool
+	help
+	  Selected by architectures which support VDSO page checks
+
 endif
diff --git a/mm/mprotect.c b/mm/mprotect.c
index ab709023e9aa..838f42b25805 100644
--- a/mm/mprotect.c
+++ b/mm/mprotect.c
@@ -128,6 +128,15 @@ static unsigned long change_pte_range(struct vm_area_struct *vma, pmd_t *pmd,
 				 * things like COW could be properly
 				 * handled.
 				 */
+
+				/* Ignoring the above comment and setting 
+				 * the page writable here because we call
+				 * uffd write protect independently and  
+				 * we don't want an extra fault after that; 
+				 * this might disturb functionality like COW 
+				 * as stated above but not worrying about it now. */
+				ptent = pte_mkwrite(ptent);
+
 				ptent = pte_clear_uffd_wp(ptent);
 			}
 
-- 
2.25.1

